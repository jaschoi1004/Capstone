---
title: "STAT 4893W"
author: "Jong Hyun Choi"
date: "9/19/2021"
output: html_document
---

```{r}
## combine two 2018 Excel sheets together 
library(readxl)
first1 = read_xlsx("2018_10.xlsx", col_names = TRUE)
first2 = read_xlsx("2018_12.xlsx", col_names = TRUE)
```


```{r}
## inner join by CPSIDP column 
library(dplyr)
data1 = inner_join(first1, first2, by = "CPSIDP")
```

```{r}
## do the same for 2019 Excel sheets
second1 = read_xlsx("2019_10.xlsx", col_names = T)
second2 = read_xlsx("2019_12.xlsx", col_names = T)

```

```{r}
## inner join by CPSIDP column
data2 = inner_join(second1, second2, by = "CPSIDP")
```


```{r}
## got rid of all the columns that had all missing values
data1.mmissing = data1[, colSums(is.na(data1)) ==0 ]
data2.mmissing = data2[, colSums(is.na(data2)) ==0 ]
```


```{r}
## take out columns that I don't need
data1 = select(data1.mmissing, -YEAR.y, -SERIAL.y, -HWTFINL.y, -FAMINC.y, -PERNUM.y, -WTFINL.y, -AGE.y, -SEX.y, -RACE.y)
data2 =  select(data2.mmissing, -YEAR.y, -SERIAL.y, -HWTFINL.y, -FAMINC.y, -PERNUM.y, -WTFINL.y, -AGE.y, -SEX.y, -RACE.y)
```



```{r}
## change CPSIDP from character to numeric 
data1$CPSIDP = as.numeric(as.character(data1$CPSIDP))
data2$CPSIDP = as.numeric(as.character(data2$CPSIDP))

## can check to see if all the variables are numeric 
sapply(data1, class)
sapply(data2, class)

```


```{r}
## deleting rows where the following variables are not equal to 99 
data1 = data1 %>% filter(FAMINC.x != 995 & FAMINC.x != 996 & FAMINC.x != 997 & FAMINC.x != 999 & FSSTATUS.y != 99 & FSRAWSCR.y!=99 & FSRAWSCR.y !=98 & FSSTATUSD.y !=99 & FSSTATUSD.y != 98 & EDFULL.x != 99 & EDTYPE.x != 99 & EDVOCA.x!= 99)

data2 = data2 %>% filter(FAMINC.x != 995 & FAMINC.x != 996 & FAMINC.x != 997 & FAMINC.x != 999 & FSSTATUS.y != 99 & FSRAWSCR.y!=99 & FSRAWSCR.y !=98 & FSSTATUSD.y !=99 & FSSTATUSD.y != 98 & EDFULL.x != 99 & EDTYPE.x != 99 & EDVOCA.x!= 99)
```


```{r} 
## the levels that show have 98 in them 
data1$FSSTATUSD.y = factor(data1$FSSTATUSD.y)
data1$FAMINC.x = factor(data1$FAMINC.x)
data1$AGE.x = factor(data1$AGE.x)
data1$SEX.x = factor(data1$SEX.x)
data1$RACE.x = factor(data1$RACE.x)
data1$EDFULL.x = factor(data1$EDFULL.x)
data1$EDTYPE.x = factor(data1$EDTYPE.x)
data1$EDVOCA.x = factor(data1$EDVOCA.x)
data1$FSRAWSCR.y = factor(data1$FSRAWSCR.y)
data1$FSSTATUS.y = factor(data1$FSSTATUS.y)
data1$YEAR.x = factor(data1$YEAR.x)

data2$FSSTATUSD.y = factor(data2$FSSTATUSD.y)
data2$FAMINC.x = factor(data2$FAMINC.x)
data2$AGE.x = factor(data2$AGE.x)
data2$SEX.x = factor(data2$SEX.x)
data2$RACE.x = factor(data2$RACE.x)
data2$EDFULL.x = factor(data2$EDFULL.x)
data2$EDTYPE.x = factor(data2$EDTYPE.x)
data2$EDVOCA.x = factor(data2$EDVOCA.x)
data2$FSRAWSCR.y = factor(data2$FSRAWSCR.y)
data2$FSSTATUS.y = factor(data2$FSSTATUS.y)
data2$YEAR.x = factor(data2$YEAR.x)
```



```{r}
## combine the two datasets
data3 = rbind(data1, data2)

library(randomForest)

#=--------------------------------------------------------------------------------------

## seeing the imbalance between the different levels of food insecurity in a barplot 
b = barplot(prop.table(table(data3$FSSTATUSD.y)), col = "light blue")
b

## seeing the proportion numbers from the barplot 
prop.table(table(data3$FSSTATUSD.y))

```


```{r}
## splitting the data in to train and test datasets 
ind = sample(2, nrow(data3), replace = TRUE, prob = c(0.7, 0.3))
ind

train = data3[ind ==1,]
test = data3[ind ==2, ]

table(train$FSSTATUSD.y)
table(test$FSSTATUSD.y)

## Random Forest
rftrain = randomForest(FSSTATUSD.y ~ FAMINC.x + EDTYPE.x + EDFULL.x + EDVOCA.x + RACE.x, data = train)
rftrain

## random forest Confusion Matrix 
confusionMatrix(predict(rftrain, test), test$FSSTATUSD.y)

```


```{r}
## Using Ranger to do barplot and find variable of importance
mod7 = ranger(FSSTATUSD.y ~ FAMINC.x + EDTYPE.x + EDFULL.x + EDVOCA.x + RACE.x, data = train, ntree = 1000, importance = "impurity")

varimp7 = mod7$variable.importance


barplot(varimp7, las = 1, col = "light blue",names.arg = c("Family Income", "Education Type", "Full/Part Time", "Vocational Training", "Race"), cex.names = 0.7)

```


```{r}
## showing how much the model accuracy would decrease if we drop that variable 
importance(mod7)
```


```{r}
##  Measure of variable importance based on the Gini impurity index used for the calculation of splits in trees.
## From the results, we can see that famine and race had the most impact whereas the education variables not so much. 
varImpPlot(rftrain)
```


```{r}
## randomly sampling 63 observations from each of the levels 

## put 63 observations of each level into aa 
aa = data3 %>% group_by(FSSTATUSD.y) %>% sample_n(63)

## randomly mix the orders 
aa = aa[sample(1:nrow(aa)), ]
```

```{r}

ind2 = sample(2, nrow(aa), replace = TRUE, prob = c(0.7,0.3))
ind2

train2 = aa[ind2 ==1,]
test2 = aa[ind2 ==2,]

## running the dataset with more balance 
rf3 = randomForest(FSSTATUSD.y ~ FAMINC.x + EDTYPE.x + EDFULL.x + EDVOCA.x + RACE.x, data = aa , ntree = 1000, importance = TRUE)
rf3 

confusionMatrix(predict(rf3, test), test$FSSTATUSD.y)


library(ranger)
rf4 = ranger(FSSTATUSD.y ~ FAMINC.x + EDTYPE.x + EDFULL.x + EDVOCA.x + RACE.x, data = aa, importance = "impurity")

varimp4 = rf4$variable.importance

## barplot of variable of importance 
barplot(varimp4, las = 1, col = "light blue", names.arg = c("Family Income", "Education Type", "Full/Part Time", "Vocational Training", "Race"),cex.names = 0.71)

```

```{r}
## visualization for linear regression including 4 variables 

g = ggplot(data3, aes(FSSTATUSD.y))
g + geom_bar(aes(fill = EDFULL.x, width = 0.5 + theme(axis.text.x = element_text(angle = 65, vjust = 0.6))), position = "dodge")

g2 = ggplot(data3, aes(FSSTATUSD.y))
g2 + geom_bar(aes(fill = EDTYPE.x , width = 0.5 + theme(axis.text.x = element_text(angle = 65, vjust = 0.6))), position = "dodge")

g3 = ggplot(data3, aes(FSSTATUSD.y))
g3 + geom_bar(aes(fill = EDVOCA.x, width = 0.5 + theme(axis.text.x = element_text(angle = 65, vjust = 0.6))), position = "dodge")

g4 = ggplot(data3, aes(FSSTATUSD.y))
g4 + geom_bar(aes(fill = RACE.x, width = 0.5 + theme(axis.text.x = element_text(angle = 65, vjust = 0.6))))

g5 = ggplot(data3, aes(FSSTATUSD.y))
g5 + geom_bar(aes(fill = FAMINC.x, width = 0.5 + theme(axis.text.x = element_text(angle = 65, vjust = 0.6))))

```



```{r}
# SMOTE Method 
library(caTools)

smotedata = as.data.frame(data3)
split = sample.split(smotedata$FSSTATUSD.y, SplitRatio = 0.7)

dresstrain = subset(smotedata, split ==TRUE) 
dresstest = subset(smotedata, split == FALSE)

as.data.frame(table(dresstrain$FSSTATUSD.y))


library(DMwR) 
dresstrain$FSSTATUSD.y = as.factor(dresstrain$FSSTATUSD.y)

## Use SMOTE Method
final_imbalance = SMOTE(FSSTATUSD.y ~ FAMINC.x + EDTYPE.x + EDFULL.x + EDVOCA.x + RACE.x, data = dresstrain, perc.over = 1000, perc.under = 200, k = 10)

## USing SMOTE Method into Random Forest
finalmod = randomForest(FSSTATUSD.y ~ FAMINC.x + EDTYPE.x + EDFULL.x + EDVOCA.x + RACE.x, data = final_imbalance, ntree = 1000)

varImpPlot(finalmod)

mod4 = ranger(FSSTATUSD.y ~ FAMINC.x + EDTYPE.x + EDFULL.x + EDVOCA.x + RACE.x, data = final_imbalance, importance = "impurity")
varimp3 = mod4$variable.importance

predicted.response = predict(finalmod, dresstest)

confusionMatrix(data = predicted.response, reference = as.factor(dresstest$FSSTATUSD.y))


rf5 = ranger(FSSTATUSD.y ~ FAMINC.x + EDTYPE.x + EDFULL.x + EDVOCA.x + RACE.x, data = final_imbalance, importance = "impurity")
varimp5 = rf5$variable.importance

```










